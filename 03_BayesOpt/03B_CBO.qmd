---
title: "Constraint Bayesian Optimization (CBO)"
subtitle: |
date: '`r Sys.Date()`'
author: Nam-Anh Tran
format:
  html: 
    theme: darkly
    toc: false
fontsize: 12pt
reference-location: margin
citation-location: margin
number-sections: true
fig-cap-location: bottom
fig-height: 6
fig-width: 8.5
link-citations: true
linkcolor: deeppink
indent: true
classoption: [onecolumn, portrait]
bibliography: 03_references.bib
csl: ../vancouver.csl
editor: source
editor_options: 
  chunk_output_type: console
execute: 
  eval: true
---

\renewcommand{\bf}[1]{\boldsymbol{#1}}

Returning to the setting where our interest lies in finding 
$$
\hat{x} = \arg\min_{x \in \mathcal X} f(x).
$$

Sometimes, the domain $\mathcal X$, in practice, could not access but $\mathcal X_s \subset \mathcal X$. We then have an constraint $c(x)$, which, for simplicity, is assumed binary. Thus, the optimization is now 
$$
\hat x = \arg\min_{x \in \mathcal X} f(x), \quad \text{ s.t } c(x) \le 0.
$$

In this setting, the optimization requires a new acquisition function instead of EI, which reflects both $f(x)$ and the constraint $c(x)$. What was introduced by Gramacy et al.[@gramacy2020surrogates] is the expected feasible improvement (EFI):
$$
EFI(x) = \mathbb{E}[I(x)]\bf 1_{c(x) \le 0}(x),
$$
or the integrated expected conditional improvement (IECI)
$$
IECI(x_{n+1}) = - \int_{\mathcal X} \mathbb E[I(x \vert x_{n+1})]\bf1_{c(x) \le 0}(x)dx = -\int_{c(x) \le 0} \mathbb E[I(x \vert x_{n+1})] dx
$$













