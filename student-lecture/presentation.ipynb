{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Bayesian model selection for generalized linear mixed models\"\n",
        "subtitle: 'Authors: Shuangshuang Xu et. al.'\n",
        "author: \"Presenters: Qicheng Zhao, Nam-Anh Tran\"\n",
        "format: \n",
        "  revealjs:\n",
        "    theme: night\n",
        "    transition: fade\n",
        "    slide-number: true\n",
        "    show-slide-number: print\n",
        "editor: source\n",
        "fontsize: 18pt\n",
        "---"
      ],
      "id": "d6474aa9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{css}\n",
        "\n",
        ".scrolling {\n",
        "  max-height: 500px;\n",
        "  overflow-y: auto;\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "# Agenda \n",
        "\n",
        "1. Theory\n",
        "   - Pseudo likelihood function for generalized linear mixed models\n",
        "   - Model selection\n",
        "2. Simulation study \n",
        "\n",
        "# Pseudo likelihood function for generalized linear mixed models\n",
        "\n",
        "## GLMM\n",
        "\n",
        "Consider the model:\n",
        "\n",
        "$$\n",
        "f(y_i|\\eta_i) = \\exp[y_i\\eta_i - B_i(\\eta_i) + C_i(y_i)], \\quad i = 1,2,\\dots,n\n",
        "$$\n",
        "\n",
        "where $\\mu_i = B'_i(\\eta_i)$ and $v_i = B_i''(\\eta_i)$, and \n",
        "\n",
        "$$\n",
        "\\eta_i = \\boldsymbol x_i^{\\top}\\boldsymbol\\beta + \\sum_j^Q\\boldsymbol z_{ij}^{\\top}\\boldsymbol\\alpha_j\n",
        "$$\n",
        "\n",
        "Let $\\boldsymbol\\alpha$ is a vector of random effects. Then \n",
        "\n",
        "$$\n",
        "\\boldsymbol\\alpha|\\boldsymbol\\tau \\sim N(\\boldsymbol 0, \\boldsymbol\\tau\\boldsymbol\\Sigma)\n",
        "$$\n",
        "\n",
        "- If $\\boldsymbol\\alpha$ is a vector of spatial random effects that follows a sum-zero constrained Gaussian intrinsic conditional autoregressive model (ICAR).\n",
        "\n",
        "## How to define $\\boldsymbol\\Sigma$ for the sum-zero constrained Gaussian intrinsic conditional autoregressive model?  \n",
        "\n",
        "\n",
        "- Define adjacency matrix $\\boldsymbol W = [w_{ij}]$, where $w_{ij} = 1$ if region $i$ and $j$ are neighbours, and 0 otherwise. \n",
        "- Let $\\boldsymbol D_w$ is the diagonal matrix. The diagonal element is the row sum of $\\boldsymbol W$ \n",
        "- $\\boldsymbol \\Sigma$ is the pseudo-inverse of $\\boldsymbol D_w -\\boldsymbol W$.\n",
        "\n",
        "\n",
        "## Pseudo likelihood function for GLMMs\n",
        "\n",
        "- A key step in Bayesian model selection is to integrate out random effects from the likelihood function, which does not have a analytical form for GLMMs.\n",
        "- Pseudo-likelihood approach that approximates a GLMM for non-Gaussian data by computing adjusted observations that are modeled using an approximate Gaussian LMM.\n",
        "\n",
        "Specifically, we calculate this intractable likelihood function\n",
        "\n",
        "![](eq01.png){width=55% fig-align=\"center\"}\n",
        "\n",
        "\n",
        "## Pseudo likelihood function for GLMMs\n",
        "\n",
        "- The pseudo-likelihood approach is an iterative procedure.\n",
        "\n",
        "- We start with the model: \n",
        "\n",
        "$$\n",
        "\\boldsymbol y = \\boldsymbol\\mu + \\boldsymbol\\epsilon,\n",
        "$$ {#eq-01}\n",
        "\n",
        "and assume $\\widehat{\\boldsymbol\\alpha}, \\widehat{\\boldsymbol\\beta}, \\widehat{\\boldsymbol\\mu}$ and $\\widehat{\\boldsymbol V}$ are estimates of their corresponding parameters.\n",
        "\n",
        "- Using Taylor expansion (i.e. $f(x) \\approx f(x_0) + f'(x_0)(x-x_0)$) around $\\boldsymbol\\alpha$ and $\\boldsymbol\\beta$ in @eq-01, we have\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "LHS &= \n",
        "\\widehat{\\boldsymbol V}^{-1}(y - \\widehat{\\boldsymbol\\mu}) + \\widehat{\\boldsymbol V}\\widehat{\\boldsymbol\\mu}'[\\boldsymbol X\\widehat{\\boldsymbol\\beta} + \\sum_j\\boldsymbol Z_j\\widehat{\\boldsymbol\\alpha}_j]\\\\\n",
        "&=\\widehat{\\boldsymbol V}^{-1}(y - \\widehat{\\boldsymbol\\mu}) + \\boldsymbol X\\widehat{\\boldsymbol\\beta} + \\sum_j\\boldsymbol Z_j\\widehat{\\boldsymbol\\alpha}_j \\\\\n",
        "&\\doteq \\boldsymbol y^*\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$\\boldsymbol y^*$ is a vector of adjusted observations.\n",
        "\n",
        "\n",
        "## Pseudo likelihood function for GLMMs\n",
        "\n",
        "- Equating $\\boldsymbol y^*$ to the RHS, we have \n",
        "\n",
        "$$\n",
        "\\boldsymbol y^* \\approx \\boldsymbol{X\\beta} + \\sum_j \\boldsymbol Z_j\\boldsymbol\\alpha_j + \\widehat{\\boldsymbol V}^{-1}\\boldsymbol\\epsilon,\n",
        "$$ {#eq-02}\n",
        "\n",
        "where $\\boldsymbol\\alpha_j \\sim N(\\boldsymbol 0, \\tau_j\\boldsymbol\\Sigma_j)$, and $\\boldsymbol\\epsilon \\sim N(\\boldsymbol 0, \\boldsymbol V)$.\n",
        "\n",
        "Substitute $\\boldsymbol V$ with $\\widehat{\\boldsymbol V}$ in @eq-02, we have \n",
        "\n",
        "$$\n",
        "\\boldsymbol y^* \\sim N(\\boldsymbol{X\\beta}, \\sum_j\\tau_j\\boldsymbol Z_j\\boldsymbol\\Sigma_j\\boldsymbol Z_j^{\\top} + \\widehat{\\boldsymbol V}^{-1})\n",
        "$$\n",
        "\n",
        "# Model selection \n",
        "\n",
        "## Posterior model probabilities\n",
        "\n",
        "- Consider the model space $\\mathfrak{M} = \\{ M_c\\}_{c=1}^C$, where $M_c$ has $K_c$ regressors and $\\boldsymbol X_c$ is the corresponding matrix of predictors, and $\\boldsymbol\\beta_c$ is the corresponding vector of coefficients. \n",
        "\n",
        "- We integrate the likelihood based on $\\boldsymbol y^*$:\n",
        "\n",
        "$$\n",
        "p(\\boldsymbol y^*|M_c) = \\int_{\\Theta} p(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\\pi(\\boldsymbol\\beta_c,\\tau_c|M_c)d\\boldsymbol\\beta_cd\\boldsymbol\\tau_c\n",
        "$$ {#eq-03}\n",
        "\n",
        "- Let $\\pi(M_c)$ be the prior probability of $M_c$, we have \n",
        "\n",
        "$$\n",
        "P(M_c|\\boldsymbol y^*) =\\frac{ p(\\boldsymbol y^*|M_c)\\pi(M_c)}{\\sum_{r=1}^C p(\\boldsymbol y^*|M_c)\\pi(M_c)}\n",
        "\\propto \\color{pink}{{p(\\boldsymbol y^*|M_c)\\pi(M_c)}}\n",
        "$$ {#eq-04}\n",
        "\n",
        "- @eq-04 is our primary objective. \n",
        "\n",
        "- We then need to define the priors for $\\boldsymbol\\beta, \\boldsymbol\\tau$ and $M_c$. \n",
        "\n",
        "## Priors for model parameters\n",
        "\n",
        "- Two parameters of interest are $\\boldsymbol\\beta$ and precision $1/\\boldsymbol\\tau$ where $\\boldsymbol\\beta \\perp \\boldsymbol\\tau$.\n",
        "\n",
        "- $\\boldsymbol\\beta$ follows Uniform distribution on $\\mathbb{R}^p$, i.e. $\\boldsymbol\\beta|M \\propto 1$, the flat prior.  \n",
        "- $\\pi(\\tau) \\propto (1+\\frac{\\tau}{\\alpha_{\\tau}})^{-2}$, $\\alpha_{\\tau}$ is a hyperparameter.\n",
        "- By simulation, authors show that $\\alpha_{\\tau} = 2$ works well for GLMMs. Thus, \n",
        "\n",
        "$$\n",
        "\\pi_1(\\tau|M) = \\frac{1}{2(\\tau/2+1)^2}, \\tau \\ge 0.\n",
        "$$\n",
        "\n",
        "Another choice is the half-Cauchy for $\\sqrt{\\tau}$\n",
        "\n",
        "$$\n",
        "\\pi_2(\\tau) \\propto \\frac{1}{(\\tau + 1)\\sqrt{\\tau}},\n",
        "$$\n",
        "$\\sqrt{\\tau}$ has more mass near zero and more mass for large value of $\\tau$. \n",
        "\n",
        "## Priors on the model space\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "### A \n",
        "\n",
        "- Let $K$ denote the number of candidate covariates and $Q$ denote the number of candidate random effects types. Also $K_c$ is the number of covariates  in the model $M_c$. \n",
        "- The prior probability for model $M_c$ with $K_c$ covariates is \n",
        "\n",
        "$$\n",
        "P(M_c\\text{ with } K_c \\text{ covariates}) = \\frac{1}{(K+1){K\\choose K_c}}\n",
        "$$\n",
        "\n",
        "- For random effect, there are $2^Q$ possibilities for inclusion and exclusion of random effects. \n",
        "- If $P(\\text{\"inclusion\"}) = 0.5$, then $P(M_c\\text{ with }Q_c\\text{ types of random effects}) = \\frac{1}{2^Q}$\n",
        "- Assuming a priori independence of inclusion of fixed effects and random effects, the prior probability for model $M_c$ is\n",
        "\n",
        "$$\n",
        "P(M_c) = \\frac{1}{2^Q(K+1){K\\choose K_c}}\n",
        "$$\n",
        "\n",
        "\n",
        "### B\n",
        "\n",
        "Let's consider $\\{x_1,x_2,x_3\\}$, we have \n",
        "\n",
        "- Intercept only, i.e. $M1$\n",
        "- 1 covariate: $x_1, x_2, x_3$, i.e $M2, M3, M4$\n",
        "- 2 covariates: $x_1x_2, x_2x_3, x_1x_3$, i.e. $M5, M6, M7$\n",
        "- 3 covariates: $x_1x_2x_3$, i.e $M8$\n",
        "\n",
        "So, \n",
        "\n",
        "$$\n",
        "P(M = M2) = P(M \\in \\{M2,M3,M4\\})\\times P(M2|M \\in \\{M2,M3,M4\\})\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "## Integrated likelihood methods\n",
        "\n",
        "- Return @eq-03 and @eq-04. We need to calculate: \n",
        "\n",
        "![](eq02.png){width=43% fig-align=\"center\"}\n",
        "\n",
        "- $\\boldsymbol\\beta_c$ can be integrated out analytically\n",
        "\n",
        "![](eq03.png){width=43% fig-align=\"center\"}\n",
        "\n",
        "where $\\boldsymbol H_c = \\sum^{Q_c}_j (\\tau_{cj}\\boldsymbol Z_{cj}\\boldsymbol\\Sigma_{cj}\\boldsymbol Z_{cj}^{\\top}) + \\widehat{\\boldsymbol V}^{-1}$. $\\boldsymbol\\tau_c$ can't be integrated out analytically. \n",
        "\n",
        "## Integrated likelihood methods\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "### A\n",
        "\n",
        "We need to approximate the integration wrt $\\boldsymbol\\tau_c$ using Laplace method. \n",
        "\n",
        "- Transform $\\boldsymbol\\delta_c = \\ln\\boldsymbol\\tau_c$.\n",
        "- Integrate out $\\boldsymbol\\delta_c$:\n",
        "\n",
        "$$\n",
        "\\int p(\\boldsymbol y^*,\\boldsymbol\\tau_c|M_c)d\\boldsymbol\\tau_c = \\int p(\\boldsymbol y^*, e^{\\boldsymbol\\tau_c}|M_c)e^{\\boldsymbol\\tau_c}d\\boldsymbol\\tau_c\n",
        "\\approx (2\\pi)^{Q_c/2} |q''(\\widehat{\\boldsymbol\\delta}_c)|^{-1/2}e^{-q(\\widehat{\\boldsymbol\\delta}_c)}\n",
        "$$\n",
        "\n",
        "\n",
        "![](eq04.png){width=70% fig-align=\"center\"}\n",
        "\n",
        "### B\n",
        "\n",
        "#### Laplace approximation\n",
        "\n",
        "We will be concerned with integrals of the form \n",
        "\n",
        "$$\n",
        "I(t) = \\int_K h(\\boldsymbol x)e^{-tf(\\boldsymbol x)}d\\boldsymbol x\n",
        "$$\n",
        "Then, as $t$ tends to infinity, we have the following asymptotic equivalent \n",
        "\n",
        "$$\n",
        "I(t) \\approx \\frac{h(\\boldsymbol x_*)}{\\sqrt{det[f''(\\boldsymbol x_*)]}}\\Big(\\frac{2\\pi}{t}\\Big)^{d/2}e^{-tf(\\boldsymbol x_*)}\n",
        "$$\n",
        "\n",
        "**Where does it come from?** [go to this Link](https://francisbach.com/laplace-method/)\n",
        "\n",
        ":::\n",
        "\n",
        "## Fractional Bayes factors\n",
        "\n",
        "We now calculate the posterior model probabilities of interest. The the baseline model $M_l$ be the model with the largest integrated likelihood in the model space. The Bayes factor \n",
        "\n",
        "$$\n",
        "BF_{cl} = \\frac{p(\\boldsymbol y^*|M_c)}{p(\\boldsymbol y^*|M_l)}\n",
        "$$\n",
        "\n",
        "Hence,\n",
        "\n",
        "$$\n",
        "p(M_c|\\boldsymbol y^*) \\propto \\frac{p(M_c)p(\\boldsymbol y^*|M_c)}{p(\\boldsymbol y^*|M_l)} \\propto BF_{cl}p(M_c)\n",
        "$$\n",
        "\n",
        "since $\\pi(\\boldsymbol\\beta_c|M_c)$ is improper, $p(\\boldsymbol y^*|M_c)$ is only defined up to an unspecified constant of proportionality, and hence $BF_{cl}$. Models cannot be used to compared directly. \n",
        "\n",
        "- We then use the fractional bayes factor (FBF) to approximate the Bayes factor. \n",
        "- FBF is used to train the improper prior to obtain a meaningful Bayes factor, i.e we combine the improper prior with a fraction of the likelihood to obtain a proper distribution. \n",
        "- We then use the trained prior to compute the meaningful Bayes factor. \n",
        "\n",
        "\n",
        "## Fractional Bayes factors\n",
        "\n",
        "We train the prior with a fraction $b$ of the likelihood. The trained prior is \n",
        "\n",
        "$$\n",
        "\\pi^b (\\boldsymbol\\beta_c,\\boldsymbol\\tau_c) = \\frac{p^b(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\\pi(\\boldsymbol\\beta_c,\\boldsymbol\\tau_c|M_c)}{\\int p^b(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\\pi(\\boldsymbol\\beta_c,\\boldsymbol\\tau_c|M_c)d\\boldsymbol\\beta_c}\n",
        "$$\n",
        "\n",
        "Following O'hagan (1995), the fractional integrated likelihood is equal\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "q_c(b,\\boldsymbol y^*) &= \\int p^{1-b}(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\\pi^b(\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)d\\boldsymbol\\beta_cd\\boldsymbol\\tau_c\\\\\n",
        "&= \\int p^{1-b}(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\n",
        "\\frac{p^b(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\\pi(\\boldsymbol\\beta_c,\\boldsymbol\\tau_c|M_c)}{\\int p^b(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\\pi(\\boldsymbol\\beta_c,\\boldsymbol\\tau_c|M_c)d\\boldsymbol\\beta_c}d\\boldsymbol\\beta_cd\\boldsymbol\\tau_c\\\\\n",
        "&= \\frac{\\int p(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\\pi(\\boldsymbol\\beta_c,\\boldsymbol\\tau_c|M_c)d\\boldsymbol\\beta_c\\boldsymbol\\tau_c}{\\int p^b(\\boldsymbol y^*|\\boldsymbol\\beta_c,\\boldsymbol\\tau_c)\\pi(\\boldsymbol\\beta_c,\\boldsymbol\\tau_c|M_c)d\\boldsymbol\\beta_c\\boldsymbol\\tau_c}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "-  In GLMM applications, $b = (p+1)/n$ yields well-defined Bayes factor. \n",
        "\n",
        "## Fractional Bayes factors\n",
        "\n",
        "The FBF of $M_c$ versus $M_l$ is defined as \n",
        "\n",
        "$$\n",
        "BF_{cl}^b = \\frac{q_c(b,\\boldsymbol y^*)}{q_l(b, \\boldsymbol y^*). }\n",
        "$$\n",
        "\n",
        "The posterior probability of $M_c$ is\n",
        "\n",
        "$$\n",
        "p^b(M_c|\\boldsymbol y) = BF^b_{cl} \\times \\frac{P(M_c)}{\\sum^C_{k=1}BF_{kl}^b\\times P(M_k)}\n",
        "$$\n",
        "\n",
        "# Simulation Study \n",
        "\n",
        "\n",
        "\n",
        "## {.scrollable }\n",
        "\n",
        "\n",
        "We utilize the function `GLMMselect` from the R package `GLMMselect`, which is defined as follows:\n",
        "\n",
        "$$\n",
        "\\texttt{GLMMselect(Y, X, Sigma, Z, family, prior, offset, NumofModel, pip_fixed, pip_random)}\n",
        "$$\n",
        "\n",
        "The arguments of this function are described below:\n",
        "\n",
        "-   **`Y`**: A numeric vector of binary or count data representing the response variable.\n",
        "-   **`X`**: A matrix of covariates.\n",
        "-   **`Sigma`**: A list of covariance matrices for the random effects.\n",
        "-   **`Z`**: A list of design matrices for the random effects.\n",
        "-   **`family`**: The distribution family for the response variable, either `\"bernoulli\"` or `\"poisson\"`.\n",
        "-   **`prior`**: The prior distribution for the variance components of the random effects, either `\"AR\"` or `\"HM\"`.\n",
        "-   **`offset`**: A known a priori component to be included in the linear predictor during model fitting.\n",
        "-   **`NumofModel`**: The number of models with the highest posterior probabilities to be reported.\n",
        "-   **`pip_fixed`**: A cutoff threshold; fixed effects with a posterior inclusion probability exceeding this threshold are included in the final model.\n",
        "-   **`pip_random`**: A cutoff threshold; random effects with a posterior inclusion probability exceeding this threshold are included in the final model.\n"
      ],
      "id": "71d80e44"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}